{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10722717,"sourceType":"datasetVersion","datasetId":6646997}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score, f1_score\n\n# ===============================\n# 1. Load Dataset and Preprocess\n# ===============================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visits\ndf = df[df[\"NACCVNUM\"] == 1]\n\n# Feature selection\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMOCA\", \"NACCTBI\", \"CVHATT\",\"CBSTROKE\"\n]\n\n# Feature Engineering\ndf[\"Cardio_Risk\"] = df[\"DIABETES\"].astype(float) + df[\"HYPERTEN\"].astype(float) + df[\"NACCBMI\"].astype(float)\ndf[\"Age_Education_Ratio\"] = df[\"NACCAGE\"].astype(float) / (df[\"EDUC\"].astype(float) + 1)\ndf[\"Lifestyle_Risk\"] = df[\"TOBAC100\"].astype(float) + df[\"ALCOCCAS\"].astype(float)\ndf[\"APOE_Risk\"] = (df[\"NACCNE4S\"] == 2).astype(int) + (df[\"NACCNE4S\"] == 1).astype(int) * 0.5\ndf.drop(columns=[\"NACCNE4S\"], inplace=True)\n\n# Define features and target\nengineered_features = [\"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\"]\nfeature_list = original_features + engineered_features\nX = df[feature_list]\ny = df[\"DEMENTED\"]\n\n# Identify numerical and categorical columns\nnumerical_cols = [\"NACCAGE\", \"EDUC\", \"NACCBMI\", \"NACCMOCA\",\n                  \"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\"]\ncategorical_cols = [\"SEX\", \"NACCNIHR\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n                    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCTBI\", \"CVHATT\",\"CBSTROKE\"]\n\n# ===============================\n# 2. Preprocessing Pipelines\n# ===============================\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', numerical_pipeline, numerical_cols),\n    ('cat', categorical_pipeline, categorical_cols)\n])\n\n# ===============================\n# 3. Train-Test Split\n# ===============================\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Fit preprocessor\npreprocessor.fit(X_train)\nX_train_processed = preprocessor.transform(X_train)\nX_test_processed = preprocessor.transform(X_test)\n\n# ===============================\n# 4. XGBoost Model with Tuned Hyperparameters\n# ===============================\nxgb_model = XGBClassifier(\n    n_estimators=300,\n    max_depth=6,\n    learning_rate=0.04,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    scale_pos_weight=2,\n    random_state=42,\n    use_label_encoder=False,\n    eval_metric='logloss'\n)\n\nfull_pipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', xgb_model)\n])\n\n# ===============================\n# 5. Cross-Validation\n# ===============================\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ncv_scores = cross_val_score(full_pipeline, X_train, y_train, cv=cv, scoring='accuracy')\nprint(\"\\nCross-Validation Scores:\", cv_scores)\nprint(\"Mean CV Accuracy:\", cv_scores.mean())\n\n# ===============================\n# 6. Train Model and Adjust Decision Threshold\n# ===============================\nfull_pipeline.fit(X_train, y_train)\ny_proba = full_pipeline.predict_proba(X_test)[:, 1]\n\n# Adjust Decision Threshold\nthreshold = 0.4  # Adjust as needed (0.3 → 0.35 for better precision-recall balance)\ny_pred = (y_proba >= threshold).astype(int)\n\n# ===============================\n# 7. Evaluation\n# ===============================\nprint(\"\\nTest Set Evaluation:\")\nprint(classification_report(y_test, y_pred))\nprint(\"Test Set ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n\n# Find best threshold dynamically\nbest_threshold = 0.3\nbest_f1 = 0\nfor t in np.arange(0.3, 0.5, 0.05):  # Try thresholds from 0.3 to 0.5\n    y_temp = (y_proba >= t).astype(int)\n    f1 = f1_score(y_test, y_temp)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_threshold = t\n\nprint(f\"Best Threshold: {best_threshold} with F1-score: {best_f1}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T09:14:35.193490Z","iopub.execute_input":"2025-02-15T09:14:35.193756Z","iopub.status.idle":"2025-02-15T09:14:36.105974Z","shell.execute_reply.started":"2025-02-15T09:14:35.193737Z","shell.execute_reply":"2025-02-15T09:14:36.104663Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-c871a237805c>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 1. Load Dataset and Preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# ===============================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/nacccsv/investigator_nacc68.csv\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace with actual file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Define missing value codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."],"ename":"ParserError","evalue":"Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score, f1_score\n\n# ================================\n# 1. Load Dataset and Preprocess\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visits\ndf = df[df[\"NACCVNUM\"] == 1]\n\n# Feature selection (original + additional features)\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMOCA\", \"NACCTBI\", \"CVHATT\",\"CBSTROKE\"\n    \"CVAFIB\", \"PD\", \"SEIZURES\", \"TRAUMBRF\", \"HYPERCHO\"\n]\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOCCAS\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCTBI\", \"CVHATT\",\n    \"CVAFIB\", \"PD\", \"SEIZURES\", \"TRAUMBRF\", \"HYPERCHO\"\n]\n\n# Feature Engineering\ndf[\"Cardio_Risk\"] = df[\"DIABETES\"].astype(float) + df[\"HYPERTEN\"].astype(float) + df[\"NACCBMI\"].astype(float)\ndf[\"Age_Education_Ratio\"] = df[\"NACCAGE\"].astype(float) / (df[\"EDUC\"].astype(float) + 1)\ndf[\"Lifestyle_Risk\"] = df[\"TOBAC100\"].astype(float) + df[\"ALCOCCAS\"].astype(float)\ndf[\"APOE_Risk\"] = (df[\"NACCNE4S\"] == 2).astype(int) + (df[\"NACCNE4S\"] == 1).astype(int) * 0.5\ndf.drop(columns=[\"NACCNE4S\"], inplace=True)\n\n# Define features and target\nengineered_features = [\"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\"]\nfeature_list = original_features + engineered_features\nX = df[feature_list]\ny = df[\"DEMENTED\"]\n\n# Identify numerical and categorical columns\nnumerical_cols = [\"NACCAGE\", \"EDUC\", \"NACCBMI\", \"NACCMOCA\",\n                  \"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\"]\ncategorical_cols = [\"SEX\", \"NACCNIHR\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n                    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCTBI\", \"CVHATT\",\"CBSTROKE\"]\n\n# ================================\n# 2. Preprocessing Pipelines\n# ================================\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', numerical_pipeline, numerical_cols),\n    ('cat', categorical_pipeline, categorical_cols)\n])\n\n# ================================\n# 3. Train-Test Split\n# ================================\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Fit preprocessor\npreprocessor.fit(X_train)\nX_train_processed = preprocessor.transform(X_train)\nX_test_processed = preprocessor.transform(X_test)\n\n# ================================\n# 4. ANN Model Definition\n# ================================\ndef build_ann_model(input_shape):\n    model = Sequential([\n        Dense(128, activation='relu', input_shape=(input_shape,)),\n        Dropout(0.3),\n        Dense(64, activation='relu'),\n        Dropout(0.2),\n        Dense(32, activation='relu'),\n        Dense(1, activation='sigmoid')  # Binary classification\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\n# Build model\ninput_shape = X_train_processed.shape[1]\nann_model = build_ann_model(input_shape)\n\n# ================================\n# 5. Model Training\n# ================================\nhistory = ann_model.fit(X_train_processed, y_train, \n                        epochs=50, batch_size=32, \n                        validation_data=(X_test_processed, y_test), \n                        verbose=1)\n\n# ================================\n# 6. Evaluation\n# ================================\ny_proba = ann_model.predict(X_test_processed).flatten()\nthreshold = 0.35  # Can be adjusted dynamically\ny_pred = (y_proba >= threshold).astype(int)\n\nprint(\"\\nTest Set Evaluation:\")\nprint(classification_report(y_test, y_pred))\nprint(\"Test Set ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n\n# Find best threshold dynamically\nbest_threshold = 0.3\nbest_f1 = 0\nfor t in np.arange(0.3, 0.5, 0.05):  # Try thresholds from 0.3 to 0.5\n    y_temp = (y_proba >= t).astype(int)\n    f1 = f1_score(y_test, y_temp)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_threshold = t\n\nprint(f\"Best Threshold: {best_threshold} with F1-score: {best_f1}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T09:14:36.106616Z","iopub.status.idle":"2025-02-15T09:14:36.106839Z","shell.execute_reply":"2025-02-15T09:14:36.106753Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score, f1_score\n\n# ================================\n# 1. Load Dataset and Preprocess\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visits\ndf = df[df[\"NACCVNUM\"] == 1]\n\n# Feature selection (original + additional features)\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMOCA\", \"NACCTBI\", \"CVHATT\",\n    \"CVAFIB\", \"HYPERCHO\",\"STROKE\",\"MEMORY\"\n]\n\n# Feature Engineering\ndf[\"Cardio_Risk\"] = df[\"DIABETES\"].astype(float) + df[\"HYPERTEN\"].astype(float) + df[\"NACCBMI\"].astype(float)\ndf[\"Age_Education_Ratio\"] = df[\"NACCAGE\"].astype(float) / (df[\"EDUC\"].astype(float) + 1)\ndf[\"Lifestyle_Risk\"] = df[\"TOBAC100\"].astype(float) + df[\"ALCOCCAS\"].astype(float)\ndf[\"APOE_Risk\"] = (df[\"NACCNE4S\"] == 2).astype(int) + (df[\"NACCNE4S\"] == 1).astype(int) * 0.5\ndf.drop(columns=[\"NACCNE4S\"], inplace=True)\n\n# Define features and target\nengineered_features = [\"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\"]\nfeature_list = original_features + engineered_features\nX = df[feature_list]\ny = df[\"DEMENTED\"]\n\n# Identify numerical and categorical columns\nnumerical_cols = [\"NACCAGE\", \"EDUC\", \"NACCBMI\", \"NACCMOCA\",\n                  \"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\"]\ncategorical_cols = [\"SEX\", \"NACCNIHR\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n                    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCTBI\", \"CVHATT\",\n                    \"CVAFIB\", \"HYPERCHO\",\"STROKE\",\"MEMORY\"]\n\n# ================================\n# 2. Preprocessing Pipelines\n# ================================\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', numerical_pipeline, numerical_cols),\n    ('cat', categorical_pipeline, categorical_cols)\n])\n\n# ================================\n# 3. Train-Test Split\n# ================================\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Fit preprocessor\npreprocessor.fit(X_train)\nX_train_processed = preprocessor.transform(X_train)\nX_test_processed = preprocessor.transform(X_test)\n\n# ================================\n# 4. Assign Sample Weights\n# ================================\n\n# 5. ANN Model Definition\n# ================================\ndef build_ann_model(input_shape):\n    model = Sequential([\n        Dense(130, activation='relu', input_shape=(input_shape,)),\n        Dropout(0.3),\n        Dense(66, activation='relu'),\n        Dropout(0.2),\n        Dense(34, activation='relu'),\n        Dense(1, activation='sigmoid')  # Binary classification\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\n# Build model\ninput_shape = X_train_processed.shape[1]\nann_model = build_ann_model(input_shape)\n\n# ================================\n# 6. Model Training with Sample Weights\n# ================================\nhistory = ann_model.fit(X_train_processed, y_train, \n                        epochs=50, batch_size=32, \n                        validation_data=(X_test_processed, y_test), \n                        verbose=1,\n                        sample_weight=sample_weights)  # Apply weighting\n\n# ================================\n# 7. Evaluation\n# ================================\ny_proba = ann_model.predict(X_test_processed).flatten()\nthreshold = 0.46 # Can be adjusted dynamically\ny_pred = (y_proba >= threshold).astype(int)\n\nprint(\"\\nTest Set Evaluation:\")\nprint(classification_report(y_test, y_pred))\nprint(\"Test Set ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n\n# Find best threshold dynamically\nbest_threshold = 0.3\nbest_f1 = 0\nfor t in np.arange(0.3, 0.5, 0.05):  # Try thresholds from 0.3 to 0.5\n    y_temp = (y_proba >= t).astype(int)\n    f1 = f1_score(y_test, y_temp)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_threshold = t\n\nprint(f\"Best Threshold: {best_threshold} with F1-score: {best_f1}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T09:22:00.497777Z","iopub.execute_input":"2025-02-15T09:22:00.498109Z","iopub.status.idle":"2025-02-15T09:24:04.405806Z","shell.execute_reply.started":"2025-02-15T09:22:00.498089Z","shell.execute_reply":"2025-02-15T09:24:04.404987Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-18-7636939da94b>:18: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8548 - loss: 0.6488 - val_accuracy: 0.9055 - val_loss: 0.2539\nEpoch 2/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.4866 - val_accuracy: 0.9058 - val_loss: 0.2577\nEpoch 3/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.4817 - val_accuracy: 0.9062 - val_loss: 0.2537\nEpoch 4/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.4736 - val_accuracy: 0.9070 - val_loss: 0.2517\nEpoch 5/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.4672 - val_accuracy: 0.9069 - val_loss: 0.2519\nEpoch 6/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.4722 - val_accuracy: 0.9066 - val_loss: 0.2510\nEpoch 7/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.4546 - val_accuracy: 0.9062 - val_loss: 0.2513\nEpoch 8/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.4548 - val_accuracy: 0.9068 - val_loss: 0.2500\nEpoch 9/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.4537 - val_accuracy: 0.9056 - val_loss: 0.2505\nEpoch 10/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.4554 - val_accuracy: 0.9062 - val_loss: 0.2509\nEpoch 11/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.4549 - val_accuracy: 0.9072 - val_loss: 0.2503\nEpoch 12/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.4608 - val_accuracy: 0.9069 - val_loss: 0.2508\nEpoch 13/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.4521 - val_accuracy: 0.9065 - val_loss: 0.2505\nEpoch 14/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.4514 - val_accuracy: 0.9068 - val_loss: 0.2516\nEpoch 15/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.4530 - val_accuracy: 0.9070 - val_loss: 0.2519\nEpoch 16/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.4546 - val_accuracy: 0.9073 - val_loss: 0.2524\nEpoch 17/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.4488 - val_accuracy: 0.9071 - val_loss: 0.2521\nEpoch 18/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.4471 - val_accuracy: 0.9075 - val_loss: 0.2518\nEpoch 19/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.4406 - val_accuracy: 0.9074 - val_loss: 0.2515\nEpoch 20/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.4379 - val_accuracy: 0.9062 - val_loss: 0.2515\nEpoch 21/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.4340 - val_accuracy: 0.9066 - val_loss: 0.2516\nEpoch 22/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.4402 - val_accuracy: 0.9070 - val_loss: 0.2523\nEpoch 23/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.4369 - val_accuracy: 0.9061 - val_loss: 0.2532\nEpoch 24/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.4391 - val_accuracy: 0.9071 - val_loss: 0.2526\nEpoch 25/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.4406 - val_accuracy: 0.9074 - val_loss: 0.2544\nEpoch 26/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.4341 - val_accuracy: 0.9070 - val_loss: 0.2538\nEpoch 27/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.4355 - val_accuracy: 0.9059 - val_loss: 0.2557\nEpoch 28/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.4407 - val_accuracy: 0.9073 - val_loss: 0.2556\nEpoch 29/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.4338 - val_accuracy: 0.9067 - val_loss: 0.2551\nEpoch 30/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.4351 - val_accuracy: 0.9067 - val_loss: 0.2560\nEpoch 31/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.4264 - val_accuracy: 0.9052 - val_loss: 0.2587\nEpoch 32/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.4380 - val_accuracy: 0.9059 - val_loss: 0.2548\nEpoch 33/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.4305 - val_accuracy: 0.9058 - val_loss: 0.2568\nEpoch 34/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.4335 - val_accuracy: 0.9047 - val_loss: 0.2591\nEpoch 35/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.4279 - val_accuracy: 0.9064 - val_loss: 0.2553\nEpoch 36/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.4271 - val_accuracy: 0.9055 - val_loss: 0.2590\nEpoch 37/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.4252 - val_accuracy: 0.9067 - val_loss: 0.2579\nEpoch 38/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.4282 - val_accuracy: 0.9060 - val_loss: 0.2582\nEpoch 39/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.4216 - val_accuracy: 0.9047 - val_loss: 0.2610\nEpoch 40/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.4247 - val_accuracy: 0.9059 - val_loss: 0.2593\nEpoch 41/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.4220 - val_accuracy: 0.9051 - val_loss: 0.2597\nEpoch 42/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.4271 - val_accuracy: 0.9059 - val_loss: 0.2603\nEpoch 43/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.4164 - val_accuracy: 0.9053 - val_loss: 0.2599\nEpoch 44/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.4224 - val_accuracy: 0.9045 - val_loss: 0.2615\nEpoch 45/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.4288 - val_accuracy: 0.9060 - val_loss: 0.2611\nEpoch 46/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.4191 - val_accuracy: 0.9055 - val_loss: 0.2623\nEpoch 47/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.4250 - val_accuracy: 0.9061 - val_loss: 0.2615\nEpoch 48/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.4164 - val_accuracy: 0.9063 - val_loss: 0.2626\nEpoch 49/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.4189 - val_accuracy: 0.9060 - val_loss: 0.2638\nEpoch 50/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.4178 - val_accuracy: 0.9061 - val_loss: 0.2642\n\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step\n\nTest Set Evaluation:\n              precision    recall  f1-score   support\n\n           0       0.92      0.94      0.93      7228\n           1       0.87      0.83      0.85      3436\n\n    accuracy                           0.91     10664\n   macro avg       0.90      0.89      0.89     10664\nweighted avg       0.91      0.91      0.91     10664\n\nTest Set ROC-AUC Score: 0.9499725351804167\nBest Threshold: 0.44999999999999996 with F1-score: 0.8504963698325678\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score, f1_score,confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\n# ================================\n# 1. Load Dataset and Preprocess\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visits\ndf = df[df[\"NACCVNUM\"] == 1]\n\n# Feature selection (original + additional features)\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMOCA\", \"NACCTBI\", \"CVHATT\",\n    \"CVAFIB\", \"HYPERCHO\",\"STROKE\",\"MEMORY\"\n]\n\n# Feature Engineering\ndf[\"Cardio_Risk\"] = df[\"DIABETES\"].astype(float) + df[\"HYPERTEN\"].astype(float) + df[\"NACCBMI\"].astype(float)\ndf[\"Age_Education_Ratio\"] = df[\"NACCAGE\"].astype(float) / (df[\"EDUC\"].astype(float) + 1)\ndf[\"Lifestyle_Risk\"] = df[\"TOBAC100\"].astype(float) + df[\"ALCOCCAS\"].astype(float)\ndf[\"APOE_Risk\"] = (df[\"NACCNE4S\"] == 2).astype(int) + (df[\"NACCNE4S\"] == 1).astype(int) * 0.5\ndf.drop(columns=[\"NACCNE4S\"], inplace=True)\ndf[\"Cognitive_Risk\"] = (0.5 * df[\"MEMORY\"] + 1) * (df[\"Age_Education_Ratio\"]+1)\n\n# Define features and target\n\nengineered_features = [\"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\",\"Cognitive_Risk\"]\nfeature_list = original_features + engineered_features\nfeature_list.remove(\"MEMORY\")\nX = df[feature_list]\ny = df[\"DEMENTED\"]\n\n# Identify numerical and categorical columns\nnumerical_cols = [\"NACCAGE\", \"EDUC\", \"NACCBMI\", \"NACCMOCA\",\n                  \"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\",\"Cognitive_Risk\"]\ncategorical_cols = [\"SEX\", \"NACCNIHR\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n                    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCTBI\", \"CVHATT\",\n                    \"CVAFIB\", \"HYPERCHO\",\"STROKE\"]\n\n# ================================\n# 2. Preprocessing Pipelines\n# ================================\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', numerical_pipeline, numerical_cols),\n    ('cat', categorical_pipeline, categorical_cols)\n])\n\n# ================================\n# 3. Train-Test Split\n# ================================\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n\n# Fit preprocessor\npreprocessor.fit(X_train)\nX_train_processed = preprocessor.transform(X_train)\nX_val_processed = preprocessor.transform(X_val)\nX_test_processed = preprocessor.transform(X_test)\n\n# Compute class weights for imbalance handling\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n\n# 5. ANN Model Definition\n# ================================\ndef build_ann_model(input_shape):\n    model = Sequential([\n        Dense(128, activation='relu', input_shape=(input_shape,)),\n        Dropout(0.3),\n        Dense(64, activation='relu'),\n        Dropout(0.2),\n        Dense(32, activation='relu'),\n        Dense(1, activation='sigmoid')  # Binary classification\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model\n    \ninput_shape = X_train_processed.shape[1]\nann_model = build_ann_model(input_shape)\n\n# ================================\n# 5. Model Training with Early Stopping\n# ================================\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\nhistory = ann_model.fit(X_train_processed, y_train, \n                        epochs=50, batch_size=32, \n                        validation_data=(X_val_processed, y_val), \n                        callbacks=[early_stopping],\n                        verbose=1)\n\n# ================================\n# 7. Evaluation\n# ================================\ny_proba = ann_model.predict(X_test_processed).flatten()\n\n# Tune threshold for best F1-score\nbest_threshold = 0.3\nbest_f1 = 0\nfor t in np.arange(0.3, 0.6, 0.05):\n    y_temp = (y_proba >= t).astype(int)\n    f1 = f1_score(y_test, y_temp)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_threshold = t\n\nprint(f\"Optimal Threshold: {best_threshold:.2f} with F1-score: {best_f1:.4f}\")\n\n# Apply optimal threshold\ny_pred = (y_proba >= best_threshold).astype(int)\n\n# Classification Report\nprint(\"\\nTest Set Evaluation:\")\nprint(classification_report(y_test, y_pred))\nprint(\"Test Set ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n\n\n\n# Generate Confusion Matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\n\n# Plot Confusion Matrix\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[\"No Dementia\", \"Dementia\"], \n            yticklabels=[\"No Dementia\", \"Dementia\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T10:16:04.744381Z","iopub.execute_input":"2025-02-15T10:16:04.744707Z","iopub.status.idle":"2025-02-15T10:16:43.269709Z","shell.execute_reply.started":"2025-02-15T10:16:04.744687Z","shell.execute_reply":"2025-02-15T10:16:43.268873Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-35-28efbc56be74>:21: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7714 - loss: 0.4595 - val_accuracy: 0.8810 - val_loss: 0.2883\nEpoch 2/50\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8728 - loss: 0.3046 - val_accuracy: 0.8918 - val_loss: 0.2747\nEpoch 3/50\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8842 - loss: 0.2913 - val_accuracy: 0.8940 - val_loss: 0.2758\nEpoch 4/50\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8903 - loss: 0.2791 - val_accuracy: 0.8961 - val_loss: 0.2687\nEpoch 5/50\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8925 - loss: 0.2747 - val_accuracy: 0.8963 - val_loss: 0.2643\nEpoch 6/50\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8972 - loss: 0.2640 - val_accuracy: 0.8993 - val_loss: 0.2613\nEpoch 7/50\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8961 - loss: 0.2671 - val_accuracy: 0.8949 - val_loss: 0.2711\nEpoch 8/50\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8990 - loss: 0.2619 - val_accuracy: 0.8997 - val_loss: 0.2637\nEpoch 9/50\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8973 - loss: 0.2679 - val_accuracy: 0.8986 - val_loss: 0.2613\nEpoch 10/50\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.2666 - val_accuracy: 0.8926 - val_loss: 0.2693\nEpoch 11/50\n\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.2640 - val_accuracy: 0.8983 - val_loss: 0.2650\n\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step\nOptimal Threshold: 0.35 with F1-score: 0.8384\n\nTest Set Evaluation:\n              precision    recall  f1-score   support\n\n           0       0.92      0.93      0.92      7228\n           1       0.84      0.83      0.84      3436\n\n    accuracy                           0.90     10664\n   macro avg       0.88      0.88      0.88     10664\nweighted avg       0.90      0.90      0.90     10664\n\nTest Set ROC-AUC Score: 0.94733527228544\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score, f1_score\n\n# ================================\n# 1. Load Dataset and Preprocess\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visits\ndf = df[df[\"NACCVNUM\"] == 1]\n\n# Feature selection (original + additional features)\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMOCA\", \"NACCTBI\", \"CVHATT\",\n    \"CVAFIB\", \"HYPERCHO\",\"STROKE\",\"MEMORY\"\n]\n\n# Feature Engineering\ndf[\"Cardio_Risk\"] = df[\"DIABETES\"].astype(float) + df[\"HYPERTEN\"].astype(float) + df[\"NACCBMI\"].astype(float)\ndf[\"Age_Education_Ratio\"] = df[\"NACCAGE\"].astype(float) / (df[\"EDUC\"].astype(float) + 1)\ndf[\"Lifestyle_Risk\"] = df[\"TOBAC100\"].astype(float) + df[\"ALCOCCAS\"].astype(float)\ndf[\"APOE_Risk\"] = (df[\"NACCNE4S\"] == 2).astype(int) + (df[\"NACCNE4S\"] == 1).astype(int) * 0.5\ndf.drop(columns=[\"NACCNE4S\", \"MEMORY\"], inplace=True)\n\n# Define features and target\nengineered_features = [\"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\"]\nfeature_list = original_features + engineered_features\nX = df[feature_list]\ny = df[\"DEMENTED\"]\n\n# Identify numerical and categorical columns\nnumerical_cols = [\"NACCAGE\", \"EDUC\", \"NACCBMI\", \"NACCMOCA\",\n                  \"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\"]\ncategorical_cols = [\"SEX\", \"NACCNIHR\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n                    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCTBI\", \"CVHATT\",\n                    \"CVAFIB\", \"HYPERCHO\",\"STROKE\",\"MEMORY\"]\n\n# ================================\n# 2. Preprocessing Pipelines\n# ================================\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', numerical_pipeline, numerical_cols),\n    ('cat', categorical_pipeline, categorical_cols)\n])\n\n# ================================\n# 3. Train-Test Split\n# ================================\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Fit preprocessor\npreprocessor.fit(X_train)\nX_train_processed = preprocessor.transform(X_train)\nX_test_processed = preprocessor.transform(X_test)\n\n# ================================\n# 4. Assign Sample Weights\n# ================================\n\n# 5. ANN Model Definition\n# ================================\ndef build_ann_model(input_shape):\n    model = Sequential([\n        Dense(130, activation='relu', input_shape=(input_shape,)),\n        Dropout(0.3),\n        Dense(66, activation='relu'),\n        Dropout(0.2),\n        Dense(34, activation='relu'),\n        Dense(1, activation='sigmoid')  # Binary classification\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\n# Build model\ninput_shape = X_train_processed.shape[1]\nann_model = build_ann_model(input_shape)\n\n# ================================\n# 6. Model Training with Sample Weights\n# ================================\nhistory = ann_model.fit(X_train_processed, y_train, \n                        epochs=50, batch_size=32, \n                        validation_data=(X_test_processed, y_test), \n                        verbose=1,\n                        sample_weight=sample_weights)  # Apply weighting\n\n# ================================\n# 7. Evaluation\n# ================================\ny_proba = ann_model.predict(X_test_processed).flatten()\nthreshold = 0.46 # Can be adjusted dynamically\ny_pred = (y_proba >= threshold).astype(int)\n\nprint(\"\\nTest Set Evaluation:\")\nprint(classification_report(y_test, y_pred))\nprint(\"Test Set ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n\n# Find best threshold dynamically\nbest_threshold = 0.3\nbest_f1 = 0\nfor t in np.arange(0.3, 0.5, 0.05):  # Try thresholds from 0.3 to 0.5\n    y_temp = (y_proba >= t).astype(int)\n    f1 = f1_score(y_test, y_temp)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_threshold = t\n\nprint(f\"Best Threshold: {best_threshold} with F1-score: {best_f1}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T09:22:00.497777Z","iopub.execute_input":"2025-02-15T09:22:00.498109Z","iopub.status.idle":"2025-02-15T09:24:04.405806Z","shell.execute_reply.started":"2025-02-15T09:22:00.498089Z","shell.execute_reply":"2025-02-15T09:24:04.404987Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-18-7636939da94b>:18: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8548 - loss: 0.6488 - val_accuracy: 0.9055 - val_loss: 0.2539\nEpoch 2/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.4866 - val_accuracy: 0.9058 - val_loss: 0.2577\nEpoch 3/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.4817 - val_accuracy: 0.9062 - val_loss: 0.2537\nEpoch 4/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.4736 - val_accuracy: 0.9070 - val_loss: 0.2517\nEpoch 5/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.4672 - val_accuracy: 0.9069 - val_loss: 0.2519\nEpoch 6/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.4722 - val_accuracy: 0.9066 - val_loss: 0.2510\nEpoch 7/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.4546 - val_accuracy: 0.9062 - val_loss: 0.2513\nEpoch 8/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.4548 - val_accuracy: 0.9068 - val_loss: 0.2500\nEpoch 9/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.4537 - val_accuracy: 0.9056 - val_loss: 0.2505\nEpoch 10/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.4554 - val_accuracy: 0.9062 - val_loss: 0.2509\nEpoch 11/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.4549 - val_accuracy: 0.9072 - val_loss: 0.2503\nEpoch 12/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.4608 - val_accuracy: 0.9069 - val_loss: 0.2508\nEpoch 13/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.4521 - val_accuracy: 0.9065 - val_loss: 0.2505\nEpoch 14/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.4514 - val_accuracy: 0.9068 - val_loss: 0.2516\nEpoch 15/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.4530 - val_accuracy: 0.9070 - val_loss: 0.2519\nEpoch 16/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.4546 - val_accuracy: 0.9073 - val_loss: 0.2524\nEpoch 17/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.4488 - val_accuracy: 0.9071 - val_loss: 0.2521\nEpoch 18/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.4471 - val_accuracy: 0.9075 - val_loss: 0.2518\nEpoch 19/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.4406 - val_accuracy: 0.9074 - val_loss: 0.2515\nEpoch 20/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.4379 - val_accuracy: 0.9062 - val_loss: 0.2515\nEpoch 21/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.4340 - val_accuracy: 0.9066 - val_loss: 0.2516\nEpoch 22/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.4402 - val_accuracy: 0.9070 - val_loss: 0.2523\nEpoch 23/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.4369 - val_accuracy: 0.9061 - val_loss: 0.2532\nEpoch 24/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.4391 - val_accuracy: 0.9071 - val_loss: 0.2526\nEpoch 25/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.4406 - val_accuracy: 0.9074 - val_loss: 0.2544\nEpoch 26/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.4341 - val_accuracy: 0.9070 - val_loss: 0.2538\nEpoch 27/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.4355 - val_accuracy: 0.9059 - val_loss: 0.2557\nEpoch 28/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.4407 - val_accuracy: 0.9073 - val_loss: 0.2556\nEpoch 29/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.4338 - val_accuracy: 0.9067 - val_loss: 0.2551\nEpoch 30/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.4351 - val_accuracy: 0.9067 - val_loss: 0.2560\nEpoch 31/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.4264 - val_accuracy: 0.9052 - val_loss: 0.2587\nEpoch 32/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.4380 - val_accuracy: 0.9059 - val_loss: 0.2548\nEpoch 33/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.4305 - val_accuracy: 0.9058 - val_loss: 0.2568\nEpoch 34/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.4335 - val_accuracy: 0.9047 - val_loss: 0.2591\nEpoch 35/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.4279 - val_accuracy: 0.9064 - val_loss: 0.2553\nEpoch 36/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.4271 - val_accuracy: 0.9055 - val_loss: 0.2590\nEpoch 37/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.4252 - val_accuracy: 0.9067 - val_loss: 0.2579\nEpoch 38/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.4282 - val_accuracy: 0.9060 - val_loss: 0.2582\nEpoch 39/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.4216 - val_accuracy: 0.9047 - val_loss: 0.2610\nEpoch 40/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.4247 - val_accuracy: 0.9059 - val_loss: 0.2593\nEpoch 41/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.4220 - val_accuracy: 0.9051 - val_loss: 0.2597\nEpoch 42/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.4271 - val_accuracy: 0.9059 - val_loss: 0.2603\nEpoch 43/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.4164 - val_accuracy: 0.9053 - val_loss: 0.2599\nEpoch 44/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.4224 - val_accuracy: 0.9045 - val_loss: 0.2615\nEpoch 45/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.4288 - val_accuracy: 0.9060 - val_loss: 0.2611\nEpoch 46/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.4191 - val_accuracy: 0.9055 - val_loss: 0.2623\nEpoch 47/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.4250 - val_accuracy: 0.9061 - val_loss: 0.2615\nEpoch 48/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.4164 - val_accuracy: 0.9063 - val_loss: 0.2626\nEpoch 49/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.4189 - val_accuracy: 0.9060 - val_loss: 0.2638\nEpoch 50/50\n\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.4178 - val_accuracy: 0.9061 - val_loss: 0.2642\n\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step\n\nTest Set Evaluation:\n              precision    recall  f1-score   support\n\n           0       0.92      0.94      0.93      7228\n           1       0.87      0.83      0.85      3436\n\n    accuracy                           0.91     10664\n   macro avg       0.90      0.89      0.89     10664\nweighted avg       0.91      0.91      0.91     10664\n\nTest Set ROC-AUC Score: 0.9499725351804167\nBest Threshold: 0.44999999999999996 with F1-score: 0.8504963698325678\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score, f1_score,confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\n# ================================\n# 1. Load Dataset and Preprocess\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visits\ndf = df[df[\"NACCVNUM\"] == 1]\n\n# Feature selection (original + additional features)\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMOCA\", \"NACCTBI\", \"CVHATT\",\n    \"CVAFIB\", \"HYPERCHO\",\"STROKE\"\n]\n\n# Feature Engineering\ndf[\"Cardio_Risk\"] = df[\"DIABETES\"].astype(float) + df[\"HYPERTEN\"].astype(float) + df[\"NACCBMI\"].astype(float)\ndf[\"Age_Education_Ratio\"] = df[\"NACCAGE\"].astype(float) / (df[\"EDUC\"].astype(float) + 1)\ndf[\"Lifestyle_Risk\"] = df[\"TOBAC100\"].astype(float) + df[\"ALCOCCAS\"].astype(float)\ndf[\"APOE_Risk\"] = (df[\"NACCNE4S\"] == 2).astype(int) + (df[\"NACCNE4S\"] == 1).astype(int) * 0.5\ndf[\"Cognitive_Risk\"] = (0.5 * df[\"MEMORY\"] + 1) * (df[\"Age_Education_Ratio\"]+1)\ndf[\"SEX\"] = df[\"SEX\"].map({1: 0, 2: 1})\n# Define features and target\n\nengineered_features = [\"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\",\"Cognitive_Risk\"]\n\n\nfeature_list = original_features + engineered_features\nX = df[feature_list]\ny = df[\"DEMENTED\"]\n\n# Identify numerical and categorical columns\nnumerical_cols = [\"NACCAGE\", \"EDUC\", \"NACCBMI\", \"NACCMOCA\",\n                  \"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\",\"Cognitive_Risk\"]\nbinary_cols = [\"SEX\", \"TOBAC100\", \"DEP2YRS\", \"NACCTBI\", \"NACCFAM\"]  # No One-Hot Encoding\ncategorical_cols = [ \"NACCNIHR\", \"NACCFAM\", \"ALCOHOL\",\n                    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"CVHATT\",\n                    \"CVAFIB\", \"HYPERCHO\",\"STROKE\"]\n\n# ================================\n# 2. Preprocessing Pipelines\n# ================================\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\nbinary_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent'))  # No encoding needed\n])\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', numerical_pipeline, numerical_cols),\n    ('bin', binary_pipeline, binary_cols),\n    ('cat', categorical_pipeline, categorical_cols)\n])\n\n# ================================\n# 3. Train-Test Split\n# ================================\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n\n# Fit preprocessor\npreprocessor.fit(X_train)\nX_train_processed = preprocessor.transform(X_train)\nX_val_processed = preprocessor.transform(X_val)\nX_test_processed = preprocessor.transform(X_test)\n\n# Compute class weights for imbalance handling\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n\n# 5. ANN Model Definition\n# ================================\ndef build_ann_model(input_shape):\n    model = Sequential([\n        Dense(128, activation='relu', input_shape=(input_shape,)),\n        Dropout(0.3),\n        Dense(64, activation='relu'),\n        Dropout(0.2),\n        Dense(32, activation='relu'),\n        Dense(1, activation='sigmoid')  # Binary classification\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model\n    \ninput_shape = X_train_processed.shape[1]\nann_model = build_ann_model(input_shape)\n\n# ================================\n# 5. Model Training with Early Stopping\n# ================================\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\nhistory = ann_model.fit(X_train_processed, y_train, \n                        epochs=50, batch_size=32, \n                        validation_data=(X_val_processed, y_val), \n                        callbacks=[early_stopping],\n                        verbose=1)\n\n# ================================\n# 7. Evaluation\n# ================================\ny_proba = ann_model.predict(X_test_processed).flatten()\n\n# Tune threshold for best F1-score\nbest_threshold = 0.3\nbest_f1 = 0\nfor t in np.arange(0.3, 0.6, 0.05):\n    y_temp = (y_proba >= t).astype(int)\n    f1 = f1_score(y_test, y_temp)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_threshold = t\n\nprint(f\"Optimal Threshold: {best_threshold:.2f} with F1-score: {best_f1:.4f}\")\n\n# Apply optimal threshold\ny_pred = (y_proba >= best_threshold).astype(int)\n\n# Classification Report\nprint(\"\\nTest Set Evaluation:\")\nprint(classification_report(y_test, y_pred))\nprint(\"Test Set ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n\n\n\n# Generate Confusion Matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\n\n# Plot Confusion Matrix\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[\"No Dementia\", \"Dementia\"], \n            yticklabels=[\"No Dementia\", \"Dementia\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n# Train logistic regression on MEMORY alone\nmodel = LogisticRegression()\nmodel.fit(X_train[[\"MEMORY\"]], y_train)\npreds = model.predict(X_test[[\"MEMORY\"]])\nacc = accuracy_score(y_test, preds)\n\nprint(f\"Feature: NACCAGE, Accuracy: {acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T09:44:51.238610Z","iopub.execute_input":"2025-02-15T09:44:51.238895Z","iopub.status.idle":"2025-02-15T09:44:51.264771Z","shell.execute_reply.started":"2025-02-15T09:44:51.238876Z","shell.execute_reply":"2025-02-15T09:44:51.264000Z"}},"outputs":[{"name":"stdout","text":"Feature: NACCAGE, Accuracy: 0.9011\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_classif\nimport pandas as pd\nimport numpy as np\n\n# ================================\n# 1. Load Dataset and Preprocess\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visits\ndf = df[df[\"NACCVNUM\"] == 1]\n\n# Feature selection (original + additional features)\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOCCAS\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMMSE\", \"NACCTBI\", \"CVHATT\",\n    \"CVAFIB\", \"PD\", \"SEIZURES\", \"TRAUMBRF\", \"HYPERCHO\", \"MEMORY\"\n]\n\n# Define target variable\nX = df[original_features]\ny = df[\"DEMENTED\"]\n\n# Convert categorical variables to numerical (for mutual information)\nX = X.copy()\nfor col in X.select_dtypes(include=['object', 'category']).columns:\n    X[col], _ = X[col].factorize()\n\n# Impute missing values with median\nX.fillna(X.median(), inplace=True)\n\n# ================================\n# 2. Compute Mutual Information\n# ================================\nmi_scores = mutual_info_classif(X, y, discrete_features='auto')\n\n# Create DataFrame for better visualization\nmi_df = pd.DataFrame({'Feature': original_features, 'Mutual Information': mi_scores})\nmi_df = mi_df.sort_values(by='Mutual Information', ascending=False)\n\n# Display ranked features\nprint(mi_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T09:14:36.108045Z","iopub.status.idle":"2025-02-15T09:14:36.108317Z","shell.execute_reply":"2025-02-15T09:14:36.108188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score, f1_score\n\n# ================================\n# 1. Load Dataset and Preprocess\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visits\ndf = df[df[\"NACCVNUM\"] == 1]\n\n# Feature selection\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOCCAS\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMMSE\", \"NACCTBI\", \"CVHATT\",\n    \"CVAFIB\", \"PD\", \"SEIZURES\", \"TRAUMBRF\", \"HYPERCHO\"\n]\n\n# Feature Engineering (Additive Features)\ndf[\"Cardio_Risk\"] = df[\"DIABETES\"].astype(float) + df[\"HYPERTEN\"].astype(float) + df[\"NACCBMI\"].astype(float)\ndf[\"Age_Education_Ratio\"] = df[\"NACCAGE\"].astype(float) / (df[\"EDUC\"].astype(float) + 1)\ndf[\"Lifestyle_Risk\"] = df[\"TOBAC100\"].astype(float) + df[\"ALCOCCAS\"].astype(float)\ndf[\"APOE_Risk\"] = (df[\"NACCNE4S\"] == 2).astype(int) + (df[\"NACCNE4S\"] == 1).astype(int) * 0.5\ndf.drop(columns=[\"NACCNE4S\"], inplace=True)\n\n# **Multiplicative Feature Engineering**\ndf[\"Age_Education_Mult\"] = df[\"NACCAGE\"] * df[\"EDUC\"]\ndf[\"Cardio_Lifestyle_Mult\"] = df[\"Cardio_Risk\"] * df[\"Lifestyle_Risk\"]\ndf[\"Cardio_APOE_Mult\"] = df[\"Cardio_Risk\"] * df[\"APOE_Risk\"]\ndf[\"Lifestyle_APOE_Mult\"] = df[\"Lifestyle_Risk\"] * df[\"APOE_Risk\"]\n\n# Define features and target\nengineered_features = [\n    \"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\",\n    \"Age_Education_Mult\", \"Cardio_Lifestyle_Mult\", \"Cardio_APOE_Mult\", \"Lifestyle_APOE_Mult\"\n]\nfeature_list = original_features + engineered_features\nX = df[feature_list]\ny = df[\"DEMENTED\"]\n\n# Identify numerical and categorical columns\nnumerical_cols = [\"NACCAGE\", \"EDUC\", \"NACCBMI\",\n                  \"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\",\n                  \"Age_Education_Mult\", \"Cardio_Lifestyle_Mult\", \"Cardio_APOE_Mult\", \"Lifestyle_APOE_Mult\"]\ncategorical_cols = [\"SEX\", \"NACCNIHR\", \"NACCFAM\", \"TOBAC100\", \"ALCOCCAS\",\n                    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCTBI\", \"CVHATT\",\n                    \"CVAFIB\", \"PD\", \"TRAUMBRF\", \"HYPERCHO\"]\n\n# ================================\n# 2. Preprocessing Pipelines\n# ================================\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# **SEIZURES - Special Handling (Ordinal)**\nseizures_imputer = Pipeline([\n    ('imputer', SimpleImputer(strategy='median'))  # Use median for ordinal variable\n])\n\npreprocessor = ColumnTransformer([\n    ('num', numerical_pipeline, numerical_cols),\n    ('cat', categorical_pipeline, categorical_cols),\n    ('seizures', seizures_imputer, ['SEIZURES'])  # Apply median imputation only to SEIZURES\n])\n\n# ================================\n# 3. Train-Test Split\n# ================================\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Fit preprocessor\npreprocessor.fit(X_train)\nX_train_processed = preprocessor.transform(X_train)\nX_test_processed = preprocessor.transform(X_test)\n\n# ================================\n# 4. ANN Model Definition\n# ================================\ndef build_ann_model(input_shape):\n    model = Sequential([\n        Dense(128, activation='relu', input_shape=(input_shape,)),\n        Dropout(0.3),\n        Dense(64, activation='relu'),\n        Dropout(0.2),\n        Dense(32, activation='relu'),\n        Dense(1, activation='sigmoid')  # Binary classification\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\n# Build model\ninput_shape = X_train_processed.shape[1]\nann_model = build_ann_model(input_shape)\n\n# ================================\n# 5. Model Training\n# ================================\nhistory = ann_model.fit(X_train_processed, y_train, \n                        epochs=50, batch_size=32, \n                        validation_data=(X_test_processed, y_test), \n                        verbose=1)\n\n# ================================\n# 6. Evaluation\n# ================================\ny_proba = ann_model.predict(X_test_processed).flatten()\nthreshold = 0.35  # Can be adjusted dynamically\ny_pred = (y_proba >= threshold).astype(int)\n\nprint(\"\\nTest Set Evaluation:\")\nprint(classification_report(y_test, y_pred))\nprint(\"Test Set ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n\n# Find best threshold dynamically\nbest_threshold = 0.3\nbest_f1 = 0\nfor t in np.arange(0.3, 0.5, 0.05):  # Try thresholds from 0.3 to 0.5\n    y_temp = (y_proba >= t).astype(int)\n    f1 = f1_score(y_test, y_temp)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_threshold = t\n\nprint(f\"Best Threshold: {best_threshold} with F1-score: {best_f1}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T09:14:36.108870Z","iopub.status.idle":"2025-02-15T09:14:36.109120Z","shell.execute_reply":"2025-02-15T09:14:36.108996Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n# ================================\n# 1. Load and Preprocess Dataset\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visits\ndf = df[df[\"NACCVNUM\"] == 1]\n\n# Feature selection (original + additional features)\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOCCAS\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMMSE\", \"NACCTBI\", \"CVHATT\",\n    \"CVAFIB\", \"PD\", \"SEIZURES\", \"TRAUMBRF\", \"HYPERCHO\", \"MEMORY\"\n]\n\n# Feature Engineering\ndf[\"Cardio_Risk\"] = df[\"DIABETES\"].astype(float) + df[\"HYPERTEN\"].astype(float) + df[\"NACCBMI\"].astype(float)\ndf[\"Age_Education_Ratio\"] = df[\"NACCAGE\"].astype(float) / (df[\"EDUC\"].astype(float) + 1)\ndf[\"Lifestyle_Risk\"] = df[\"TOBAC100\"].astype(float) + df[\"ALCOCCAS\"].astype(float)\ndf[\"APOE_Risk\"] = (df[\"NACCNE4S\"] == 2).astype(int) + (df[\"NACCNE4S\"] == 1).astype(int) * 0.5\ndf.drop(columns=[\"NACCNE4S\"], inplace=True)\n\n# Define features and target\nengineered_features = [\"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\"]\nfeature_list = original_features + engineered_features\nX = df[feature_list]\ny = df[\"DEMENTED\"]\n\n# Identify numerical and categorical columns\nnumerical_cols = [\"NACCAGE\", \"EDUC\", \"NACCBMI\", \"NACCMMSE\",\n                  \"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\"]\ncategorical_cols = [\"SEX\", \"NACCNIHR\", \"NACCFAM\", \"TOBAC100\", \"ALCOCCAS\",\n                    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCTBI\", \"CVHATT\",\n                    \"CVAFIB\", \"PD\", \"SEIZURES\", \"TRAUMBRF\", \"HYPERCHO\", \"MEMORY\"]\n\n# ================================\n# 2. Preprocessing Pipelines\n# ================================\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', numerical_pipeline, numerical_cols),\n    ('cat', categorical_pipeline, categorical_cols)\n])\n\n# Fit transformer to extract feature names\npreprocessor.fit(X)\n\n# Get transformed feature names (handle one-hot encoding)\nnum_feature_names = numerical_cols\ncat_feature_names = preprocessor.named_transformers_['cat'].named_steps['encoder'].get_feature_names_out(categorical_cols)\nall_feature_names = list(num_feature_names) + list(cat_feature_names)\n\n# Apply preprocessing\nX_processed = preprocessor.transform(X)\n\n# ================================\n# 3. Compute Mutual Information\n# ================================\nmi_scores = mutual_info_classif(X_processed, y, discrete_features='auto')\n\n# Create DataFrame for visualization\nmi_df = pd.DataFrame({'Feature': all_feature_names, 'Mutual Information': mi_scores})\nmi_df = mi_df.sort_values(by='Mutual Information', ascending=False)\n\n# Display results\nprint(\"\\nMutual Information Scores:\")\nprint(mi_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T09:14:38.472524Z","iopub.execute_input":"2025-02-15T09:14:38.472840Z","iopub.status.idle":"2025-02-15T09:14:41.446501Z","shell.execute_reply.started":"2025-02-15T09:14:38.472819Z","shell.execute_reply":"2025-02-15T09:14:41.445377Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-181e006eb472>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 1. Load and Preprocess Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# ================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/nacccsv/investigator_nacc68.csv\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace with actual file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Define missing value codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n","\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."],"ename":"ParserError","evalue":"Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.","output_type":"error"}],"execution_count":16}]}