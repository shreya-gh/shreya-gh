{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10722717,"sourceType":"datasetVersion","datasetId":6646997}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score, f1_score\n\n# ================================\n# 1. Load Dataset and Preprocess\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visits\ndf = df[df[\"NACCVNUM\"] == 1]\n\n# Feature selection (original + additional features)\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMOCA\", \"NACCTBI\", \"CVHATT\",\"CBSTROKE\"\n    \"CVAFIB\", \"PD\", \"SEIZURES\", \"TRAUMBRF\", \"HYPERCHO\"\n]\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOCCAS\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCTBI\", \"CVHATT\",\n    \"CVAFIB\", \"PD\", \"SEIZURES\", \"TRAUMBRF\", \"HYPERCHO\"\n]\n\n# Feature Engineering\ndf[\"Cardio_Risk\"] = df[\"DIABETES\"].astype(float) + df[\"HYPERTEN\"].astype(float) + df[\"NACCBMI\"].astype(float)\ndf[\"Age_Education_Ratio\"] = df[\"NACCAGE\"].astype(float) / (df[\"EDUC\"].astype(float) + 1)\ndf[\"Lifestyle_Risk\"] = df[\"TOBAC100\"].astype(float) + df[\"ALCOCCAS\"].astype(float)\ndf[\"APOE_Risk\"] = (df[\"NACCNE4S\"] == 2).astype(int) + (df[\"NACCNE4S\"] == 1).astype(int) * 0.5\ndf.drop(columns=[\"NACCNE4S\"], inplace=True)\n\n# Define features and target\nengineered_features = [\"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\"]\nfeature_list = original_features + engineered_features\nX = df[feature_list]\ny = df[\"DEMENTED\"]\n\n# Identify numerical and categorical columns\nnumerical_cols = [\"NACCAGE\", \"EDUC\", \"NACCBMI\", \"NACCMOCA\",\n                  \"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\"]\ncategorical_cols = [\"SEX\", \"NACCNIHR\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n                    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCTBI\", \"CVHATT\",\"CBSTROKE\"]\n\n# ================================\n# 2. Preprocessing Pipelines\n# ================================\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', numerical_pipeline, numerical_cols),\n    ('cat', categorical_pipeline, categorical_cols)\n])\n\n# ================================\n# 3. Train-Test Split\n# ================================\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Fit preprocessor\npreprocessor.fit(X_train)\nX_train_processed = preprocessor.transform(X_train)\nX_test_processed = preprocessor.transform(X_test)\n\n# ================================\n# 4. ANN Model Definition\n# ================================\ndef build_ann_model(input_shape):\n    model = Sequential([\n        Dense(128, activation='relu', input_shape=(input_shape,)),\n        Dropout(0.3),\n        Dense(64, activation='relu'),\n        Dropout(0.2),\n        Dense(32, activation='relu'),\n        Dense(1, activation='sigmoid')  # Binary classification\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\n# Build model\ninput_shape = X_train_processed.shape[1]\nann_model = build_ann_model(input_shape)\n\n# ================================\n# 5. Model Training\n# ================================\nhistory = ann_model.fit(X_train_processed, y_train, \n                        epochs=50, batch_size=32, \n                        validation_data=(X_test_processed, y_test), \n                        verbose=1)\n\n# ================================\n# 6. Evaluation\n# ================================\ny_proba = ann_model.predict(X_test_processed).flatten()\nthreshold = 0.35  # Can be adjusted dynamically\ny_pred = (y_proba >= threshold).astype(int)\n\nprint(\"\\nTest Set Evaluation:\")\nprint(classification_report(y_test, y_pred))\nprint(\"Test Set ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n\n# Find best threshold dynamically\nbest_threshold = 0.3\nbest_f1 = 0\nfor t in np.arange(0.3, 0.5, 0.05):  # Try thresholds from 0.3 to 0.5\n    y_temp = (y_proba >= t).astype(int)\n    f1 = f1_score(y_test, y_temp)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_threshold = t\n\nprint(f\"Best Threshold: {best_threshold} with F1-score: {best_f1}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T21:56:37.145269Z","iopub.execute_input":"2025-02-15T21:56:37.145671Z","iopub.status.idle":"2025-02-15T21:57:12.332344Z","shell.execute_reply.started":"2025-02-15T21:56:37.145641Z","shell.execute_reply":"2025-02-15T21:57:12.330277Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute class weights for imbalance handling\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = {0: class_weights[0], 1: class_weights[1]}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score, f1_score,confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\n# ================================\n# 1. Load Dataset and Preprocess\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visits\n\n# Feature selection (original + additional features)\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMOCA\", \"NACCTBI\", \"CVHATT\",\n    \"SEIZURES\", \"CVAFIB\", \"HYPERCHO\", \"CBSTROKE\", \"NACCMOM\", \"NACCDAD\", \"DEPOTHR\"\n]\n\nbinary_conversion_cols = [\n    \"ALCOHOL\", \"NACCTBI\", \"DIABETES\", \"HYPERTEN\", \"CVHATT\",\n    \"SEIZURES\", \"HYPERCHO\", \"CBSTROKE\", \"CVAFIB\"\n]\ndf[binary_conversion_cols] = df[binary_conversion_cols].map(lambda x: 1 if x == 1 or x == 2 else 0)\n\n# Feature Engineering\ndf[\"Cardio_Risk\"] = df[\"DIABETES\"].astype(float) + df[\"HYPERTEN\"].astype(float) + df[\"NACCBMI\"].astype(float)\ndf[\"Age_Education_Ratio\"] = df[\"NACCAGE\"].astype(float) / (df[\"EDUC\"].astype(float) + 1)\ndf[\"Lifestyle_Risk\"] = df[\"TOBAC100\"].astype(float) + df[\"ALCOHOL\"].astype(float)\ndf[\"Cognitive_Risk\"] = (0.5 * df[\"MEMORY\"]) * (df[\"Age_Education_Ratio\"])\ndf[\"NACCHIST\"] = (df[\"NACCFAM\"].astype(float) + 1) * (df[\"NACCMOM\"].astype(float) + 1) * (df[\"NACCDAD\"].astype(float) + 1)\ndf[\"SEX\"] = df[\"SEX\"].map({1: 0, 2: 1})\n\n# Define features and target\nengineered_features = [\"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"Cognitive_Risk\",\n                       \"NACCHIST\"]\nfeature_list = original_features + engineered_features\nfeature_list.remove(\"NACCMOM\")\nfeature_list.remove(\"NACCDAD\")\nfeature_list.remove(\"NACCFAM\")\ny = df[\"DEMENTED\"]\nX = df[feature_list]\n\n# Identify column types\nnumerical_cols = [\"NACCAGE\", \"EDUC\", \"NACCBMI\", \"NACCMOCA\"] + engineered_features\nbinary_cols = [\"SEX\", \"TOBAC100\", \"DEP2YRS\", \"DEPOTHR\"] + binary_conversion_cols\ncategorical_cols = [\"NACCNIHR\"]\n\n\n# ================================\n# 2. Preprocessing Pipelines\n# ================================\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\nbinary_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent'))\n])\n\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\npreprocessor = ColumnTransformer([\n    ('num', numerical_pipeline, numerical_cols),\n    ('bin', binary_pipeline, binary_cols),\n    ('cat', categorical_pipeline, categorical_cols)\n])\n# ================================\n# 3. Train-Test Split\n# ================================\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n\n# Fit preprocessor\npreprocessor.fit(X_train)\nX_train_processed = preprocessor.transform(X_train)\nX_val_processed = preprocessor.transform(X_val)\nX_test_processed = preprocessor.transform(X_test)\n\n# Compute class weights for imbalance handling\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n\n# 5. ANN Model Definition\n# ================================\ndef build_ann_model(input_shape):\n    model = Sequential([\n        Dense(128, activation='relu', input_shape=(input_shape,)),\n        Dropout(0.3),\n        Dense(64, activation='relu'),\n        Dropout(0.2),\n        Dense(32, activation='relu'),\n        Dense(1, activation='sigmoid')  # Binary classification\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model\n    \ninput_shape = X_train_processed.shape[1]\nann_model = build_ann_model(input_shape)\n\n# ================================\n# 5. Model Training with Early Stopping\n# ================================\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\nhistory = ann_model.fit(X_train_processed, y_train, \n                        epochs=50, batch_size=32, \n                        validation_data=(X_val_processed, y_val), \n                        callbacks=[early_stopping],\n                        verbose=1)\n\n# ================================\n# 7. Evaluation\n# ================================\ny_proba = ann_model.predict(X_test_processed).flatten()\n\n# Tune threshold for best F1-score\nbest_threshold = 0.3\nbest_f1 = 0\nfor t in np.arange(0.3, 0.6, 0.05):\n    y_temp = (y_proba >= t).astype(int)\n    f1 = f1_score(y_test, y_temp)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_threshold = t\n\nprint(f\"Optimal Threshold: {best_threshold:.2f} with F1-score: {best_f1:.4f}\")\n\n# Apply optimal threshold\ny_pred = (y_proba >= best_threshold).astype(int)\n\n# Classification Report\nprint(\"\\nTest Set Evaluation:\")\nprint(classification_report(y_test, y_pred))\nprint(\"Test Set ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n\n\n\n# Generate Confusion Matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\n\n# Plot Confusion Matrix\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[\"No Dementia\", \"Dementia\"], \n            yticklabels=[\"No Dementia\", \"Dementia\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:18:31.645243Z","iopub.execute_input":"2025-02-17T17:18:31.645660Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-11-2bdf5e32ef9f>:21: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8917 - loss: 0.2588 - val_accuracy: 0.9228 - val_loss: 0.2020\nEpoch 2/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9232 - loss: 0.2043 - val_accuracy: 0.9231 - val_loss: 0.2016\nEpoch 3/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.1993 - val_accuracy: 0.9249 - val_loss: 0.1993\nEpoch 4/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.1971 - val_accuracy: 0.9250 - val_loss: 0.1963\nEpoch 5/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.1952 - val_accuracy: 0.9254 - val_loss: 0.1957\nEpoch 6/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.1966 - val_accuracy: 0.9250 - val_loss: 0.1955\nEpoch 7/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.1937 - val_accuracy: 0.9257 - val_loss: 0.1953\nEpoch 8/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.1944 - val_accuracy: 0.9261 - val_loss: 0.1954\nEpoch 9/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9277 - loss: 0.1932 - val_accuracy: 0.9259 - val_loss: 0.1948\nEpoch 10/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.1945 - val_accuracy: 0.9254 - val_loss: 0.1948\nEpoch 11/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.1914 - val_accuracy: 0.9252 - val_loss: 0.1937\nEpoch 12/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.1920 - val_accuracy: 0.9261 - val_loss: 0.1934\nEpoch 13/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.1925 - val_accuracy: 0.9262 - val_loss: 0.1929\nEpoch 14/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.1908 - val_accuracy: 0.9260 - val_loss: 0.1945\nEpoch 15/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.1881 - val_accuracy: 0.9261 - val_loss: 0.1940\nEpoch 16/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.1888 - val_accuracy: 0.9257 - val_loss: 0.1923\nEpoch 17/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9283 - loss: 0.1894 - val_accuracy: 0.9261 - val_loss: 0.1958\nEpoch 18/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.1877 - val_accuracy: 0.9260 - val_loss: 0.1942\nEpoch 19/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.1899 - val_accuracy: 0.9262 - val_loss: 0.1927\nEpoch 20/50\n\u001b[1m2796/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.1899","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score, f1_score,confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\n# ================================\n# 1. Load Dataset and Preprocess\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visits\n\n# Feature selection (original + additional features)\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMOCA\", \"NACCTBI\", \"CVHATT\",\n    \"CVAFIB\", \"HYPERCHO\",\"STROKE\"\n]\n\n# Feature Engineering\ndf[\"Cardio_Risk\"] = df[\"DIABETES\"].astype(float) + df[\"HYPERTEN\"].astype(float) + df[\"NACCBMI\"].astype(float)\ndf[\"Age_Education_Ratio\"] = df[\"NACCAGE\"].astype(float) / (df[\"EDUC\"].astype(float) + 1)\ndf[\"Lifestyle_Risk\"] = df[\"TOBAC100\"].astype(float) + df[\"ALCOCCAS\"].astype(float)\ndf[\"APOE_Risk\"] = (df[\"NACCNE4S\"] == 2).astype(int) + (df[\"NACCNE4S\"] == 1).astype(int) * 0.5\ndf.drop(columns=[\"NACCNE4S\"], inplace=True)\ndf[\"Cognitive_Risk\"] = (0.5 * df[\"MEMORY\"] + 1) * (df[\"Age_Education_Ratio\"]+1)\n\n# Define features and target\n\nengineered_features = [\"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\",\"Cognitive_Risk\"]\nfeature_list = original_features + engineered_features\nX = df[feature_list]\ny = df[\"DEMENTED\"]\n\n# Identify numerical and categorical columns\nnumerical_cols = [\"NACCAGE\", \"EDUC\", \"NACCBMI\", \"NACCMOCA\",\n                  \"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\",\"Cognitive_Risk\"]\ncategorical_cols = [\"SEX\", \"NACCNIHR\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n                    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCTBI\", \"CVHATT\",\n                    \"CVAFIB\", \"HYPERCHO\",\"STROKE\"]\n\n# ================================\n# 2. Preprocessing Pipelines\n# ================================\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', numerical_pipeline, numerical_cols),\n    ('cat', categorical_pipeline, categorical_cols)\n])\n\n# ================================\n# 3. Train-Test Split\n# ================================\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n\n# Fit preprocessor\npreprocessor.fit(X_train)\nX_train_processed = preprocessor.transform(X_train)\nX_val_processed = preprocessor.transform(X_val)\nX_test_processed = preprocessor.transform(X_test)\n\n# Compute class weights for imbalance handling\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n\n# 5. ANN Model Definition\n# ================================\ndef build_ann_model(input_shape):\n    model = Sequential([\n        Dense(128, activation='relu', input_shape=(input_shape,)),\n        Dropout(0.3),\n        Dense(64, activation='relu'),\n        Dropout(0.2),\n        Dense(32, activation='relu'),\n        Dense(1, activation='sigmoid')  # Binary classification\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model\n    \ninput_shape = X_train_processed.shape[1]\nann_model = build_ann_model(input_shape)\n\n# ================================\n# 5. Model Training with Early Stopping\n# ================================\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\nhistory = ann_model.fit(X_train_processed, y_train, \n                        epochs=50, batch_size=32, \n                        validation_data=(X_val_processed, y_val), \n                        callbacks=[early_stopping],\n                        verbose=1)\n\n# ================================\n# 7. Evaluation\n# ================================\ny_proba = ann_model.predict(X_test_processed).flatten()\n\n# Tune threshold for best F1-score\nbest_threshold = 0.3\nbest_f1 = 0\nfor t in np.arange(0.3, 0.6, 0.05):\n    y_temp = (y_proba >= t).astype(int)\n    f1 = f1_score(y_test, y_temp)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_threshold = t\n\nprint(f\"Optimal Threshold: {best_threshold:.2f} with F1-score: {best_f1:.4f}\")\n\n# Apply optimal threshold\ny_pred = (y_proba >= best_threshold).astype(int)\n\n# Classification Report\nprint(\"\\nTest Set Evaluation:\")\nprint(classification_report(y_test, y_pred))\nprint(\"Test Set ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n\n\n\n# Generate Confusion Matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\n\n# Plot Confusion Matrix\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[\"No Dementia\", \"Dementia\"], \n            yticklabels=[\"No Dementia\", \"Dementia\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T12:30:22.958203Z","iopub.execute_input":"2025-02-17T12:30:22.958478Z","iopub.status.idle":"2025-02-17T12:35:23.681284Z","shell.execute_reply.started":"2025-02-17T12:30:22.958453Z","shell.execute_reply":"2025-02-17T12:35:23.680066Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-1-9fac02840e00>:21: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8784 - loss: 0.2897 - val_accuracy: 0.9220 - val_loss: 0.2045\nEpoch 2/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9204 - loss: 0.2107 - val_accuracy: 0.9229 - val_loss: 0.2011\nEpoch 3/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9232 - loss: 0.2041 - val_accuracy: 0.9240 - val_loss: 0.1993\nEpoch 4/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.2011 - val_accuracy: 0.9240 - val_loss: 0.1996\nEpoch 5/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2031 - val_accuracy: 0.9247 - val_loss: 0.1978\nEpoch 6/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9245 - loss: 0.2007 - val_accuracy: 0.9244 - val_loss: 0.1984\nEpoch 7/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.2011 - val_accuracy: 0.9246 - val_loss: 0.1980\nEpoch 8/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9246 - loss: 0.1986 - val_accuracy: 0.9250 - val_loss: 0.1966\nEpoch 9/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.1939 - val_accuracy: 0.9251 - val_loss: 0.1971\nEpoch 10/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.1977 - val_accuracy: 0.9248 - val_loss: 0.1966\nEpoch 11/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.1956 - val_accuracy: 0.9247 - val_loss: 0.1960\nEpoch 12/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.1968 - val_accuracy: 0.9247 - val_loss: 0.1953\nEpoch 13/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.1942 - val_accuracy: 0.9255 - val_loss: 0.1955\nEpoch 14/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.1928 - val_accuracy: 0.9251 - val_loss: 0.1965\nEpoch 15/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.1953 - val_accuracy: 0.9248 - val_loss: 0.1969\nEpoch 16/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.1925 - val_accuracy: 0.9256 - val_loss: 0.1950\nEpoch 17/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.1905 - val_accuracy: 0.9256 - val_loss: 0.1944\nEpoch 18/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.1942 - val_accuracy: 0.9254 - val_loss: 0.1959\nEpoch 19/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.1924 - val_accuracy: 0.9258 - val_loss: 0.1944\nEpoch 20/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.1914 - val_accuracy: 0.9258 - val_loss: 0.1941\nEpoch 21/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.1926 - val_accuracy: 0.9245 - val_loss: 0.1965\nEpoch 22/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.1908 - val_accuracy: 0.9255 - val_loss: 0.1937\nEpoch 23/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.1920 - val_accuracy: 0.9247 - val_loss: 0.1963\nEpoch 24/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.1912 - val_accuracy: 0.9264 - val_loss: 0.1930\nEpoch 25/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.1872 - val_accuracy: 0.9253 - val_loss: 0.1947\nEpoch 26/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9288 - loss: 0.1874 - val_accuracy: 0.9253 - val_loss: 0.1956\nEpoch 27/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.1893 - val_accuracy: 0.9261 - val_loss: 0.1936\nEpoch 28/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.1902 - val_accuracy: 0.9257 - val_loss: 0.1946\nEpoch 29/50\n\u001b[1m3725/3725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9285 - loss: 0.1885 - val_accuracy: 0.9262 - val_loss: 0.1943\n\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\nOptimal Threshold: 0.45 with F1-score: 0.8719\n\nTest Set Evaluation:\n              precision    recall  f1-score   support\n\n           0       0.94      0.95      0.95     28072\n           1       0.88      0.86      0.87     11654\n\n    accuracy                           0.93     39726\n   macro avg       0.91      0.91      0.91     39726\nweighted avg       0.93      0.93      0.93     39726\n\nTest Set ROC-AUC Score: 0.9694870508882427\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n# Train logistic regression on MEMORY alone\nmodel = LogisticRegression()\nmodel.fit(X_train[[\"MEMORY\"]], y_train)\npreds = model.predict(X_test[[\"MEMORY\"]])\nacc = accuracy_score(y_test, preds)\n\nprint(f\"Feature: NACCAGE, Accuracy: {acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T09:44:51.238610Z","iopub.execute_input":"2025-02-15T09:44:51.238895Z","iopub.status.idle":"2025-02-15T09:44:51.264771Z","shell.execute_reply.started":"2025-02-15T09:44:51.238876Z","shell.execute_reply":"2025-02-15T09:44:51.264000Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score, f1_score,confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\n# ================================NEW YES\n# 1. Load Dataset and Preprocess\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visors \ndf = df[df[\"NACCVNUM\"] == 1]\n\n# Feature selection (original + additional features)\n# Original Features\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMOCA\", \"NACCTBI\", \"CVHATT\",\n    \"SEIZURES\", \"CVAFIB\", \"HYPERCHO\", \"CBSTROKE\", \"NACCMOM\", \"NACCDAD\",\"DEPOTHR\",\"MEMORY\"\n]\n\n# Convert categorical variables to binary (1 if present, 0 otherwise)\nbinary_conversion_cols = [\n    \"ALCOHOL\", \"NACCTBI\", \"DIABETES\", \"HYPERTEN\", \"CVHATT\",\n    \"SEIZURES\", \"HYPERCHO\", \"CBSTROKE\", \"CVAFIB\"\n]\ndf[binary_conversion_cols] = df[binary_conversion_cols].applymap(lambda x: 1 if x > 0 else 0)\n\n# Feature Engineering\ndf[\"Cardio_Risk\"] = df[\"DIABETES\"].astype(float) + df[\"HYPERTEN\"].astype(float) + df[\"NACCBMI\"].astype(float)\ndf[\"Age_Education_Ratio\"] = df[\"NACCAGE\"].astype(float) / (df[\"EDUC\"].astype(float) + 1)\ndf[\"Lifestyle_Risk\"] = df[\"TOBAC100\"].astype(float) + df[\"ALCOHOL\"].astype(float)\ndf[\"APOE_Risk\"] = (2 * (df[\"NACCNE4S\"] == 2)).astype(int) + (df[\"NACCNE4S\"] == 1).astype(int)\ndf[\"Cognitive_Risk\"] = (0.5 * df[\"MEMORY\"]) * (df[\"Age_Education_Ratio\"])\ndf[\"NACCHIST\"]= (df[\"NACCFAM\"].astype(float)+1) * (df[\"NACCMOM\"].astype(float)+1) * (df[\"NACCDAD\"].astype(float)+1)\ndf[\"Cognitive_AgeEdu_Interaction\"] = (df[\"Cognitive_Risk\"].astype(float) + 1) * (df[\"Age_Education_Ratio\"].astype(float) + 1)\ndf[\"Education_Cognition\"] = df[\"EDUC\"] + df[\"NACCMOCA\"]\ndf[\"Cardio_Lifestyle_Interaction\"] = (df[\"Cardio_Risk\"] + 1) * (df[\"Lifestyle_Risk\"] + 1)\ndf[\"Dep_Lifestyle_Interaction\"] = (df[\"DEP2YRS\"] + 1) * (df[\"Lifestyle_Risk\"] + 1)\ndf[\"Dep_Cardio_Impact\"] = (0.6 * (df[\"DEP2YRS\"] + 1)) + (0.4 * (df[\"Cardio_Risk\"] + 1))\ndf[\"SEX\"] = df[\"SEX\"].map({1: 0, 2: 1})\n\n# Define features and target\nengineered_features = [\"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\", \"Cognitive_Risk\",\"NACCHIST\",\"Cognitive_AgeEdu_Interaction\",\"Education_Cognition\",\n                  \"Cardio_Lifestyle_Interaction\",\"Dep_Lifestyle_Interaction\",\"Dep_Cardio_Impact\"]\nfeature_list = original_features + engineered_features\nX = df[feature_list]\nfeature_list.remove(\"MEMORY\")\nfeature_list.remove(\"NACCMOM\")\nfeature_list.remove(\"NACCDAD\")\nfeature_list.remove(\"NACCFAM\")\ny = df[\"DEMENTED\"]\n\n# Identify numerical and categorical columns\nnumerical_cols = [\"NACCAGE\", \"EDUC\", \"NACCBMI\", \"NACCMOCA\",\n                  \"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\", \"Cognitive_Risk\",\"NACCHIST\",\"Cognitive_AgeEdu_Interaction\",\"Education_Cognition\",\n                  \"Cardio_Lifestyle_Interaction\",\"Dep_Lifestyle_Interaction\",\"Dep_Cardio_Impact\"]\nbinary_cols = [\"SEX\", \"TOBAC100\", \"DEP2YRS\", \"DEPOTHR\",\"ALCOHOL\", \"NACCTBI\", \"DIABETES\", \"HYPERTEN\", \"CVHATT\",\n    \"SEIZURES\", \"HYPERCHO\", \"CBSTROKE\", \"CVAFIB\"]  # No One-Hot Encoding\ncategorical_cols = [ \"NACCNIHR\"]\n\n# ================================\n# 2. Preprocessing Pipelines\n# ================================\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\nbinary_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent'))  # No encoding needed\n])\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', numerical_pipeline, numerical_cols),\n    ('bin', binary_pipeline, binary_cols),\n    ('cat', categorical_pipeline, categorical_cols)\n])\n\n# ================================\n# 3. Train-Test Split\n# ================================\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n\n# Fit preprocessor\npreprocessor.fit(X_train)\nX_train_processed = preprocessor.transform(X_train)\nX_val_processed = preprocessor.transform(X_val)\nX_test_processed = preprocessor.transform(X_test)\n\n# Compute class weights for imbalance handling\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n\n# 5. ANN Model Definition\n# ================================\ndef build_ann_model(input_shape):\n    model = Sequential([\n        Dense(128, activation='relu', input_shape=(input_shape,)),\n        Dropout(0.3),\n        Dense(64, activation='relu'),\n        Dropout(0.2),\n        Dense(32, activation='relu'),\n        Dense(1, activation='sigmoid')  # Binary classification\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model\n    \ninput_shape = X_train_processed.shape[1]\nann_model = build_ann_model(input_shape)\n\n# ================================\n# 5. Model Training with Early Stopping\n# ================================\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\nhistory = ann_model.fit(X_train_processed, y_train, \n                        epochs=50, batch_size=32, \n                        validation_data=(X_val_processed, y_val), \n                        callbacks=[early_stopping],\n                        verbose=1)\n\n# ================================\n# 7. Evaluation\n# ================================\ny_proba = ann_model.predict(X_test_processed).flatten()\n\n# Tune threshold for best F1-score\nbest_threshold = 0.3\nbest_f1 = 0\nfor t in np.arange(0.3, 0.6, 0.05):\n    y_temp = (y_proba >= t).astype(int)\n    f1 = f1_score(y_test, y_temp)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_threshold = t\n\nprint(f\"Optimal Threshold: {best_threshold:.2f} with F1-score: {best_f1:.4f}\")\n\n# Apply optimal threshold\ny_pred = (y_proba >= best_threshold).astype(int)\n\n# Classification Report\nprint(\"\\nTest Set Evaluation:\")\nprint(classification_report(y_test, y_pred))\nprint(\"Test Set ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n\n\n\n# Generate Confusion Matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\n\n# Plot Confusion Matrix\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[\"No Dementia\", \"Dementia\"], \n            yticklabels=[\"No Dementia\", \"Dementia\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T10:44:00.610311Z","iopub.execute_input":"2025-02-16T10:44:00.610717Z","iopub.status.idle":"2025-02-16T10:45:35.073478Z","shell.execute_reply.started":"2025-02-16T10:44:00.610686Z","shell.execute_reply":"2025-02-16T10:45:35.072187Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import classification_report, roc_auc_score, f1_score,confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\n# ================================\n# 1. Load Dataset and Preprocess\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visors \ndf = df[df[\"NACCVNUM\"] == 1]\n\n# Feature selection (original + additional features)\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOHOL\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMOCA\", \"NACCTBI\", \"CVHATT\",\n    \"SEIZURES\",\"CVAFIB\",\"HYPERCHO\",\"CBSTROKE\",\"NACCMOM\",\"NACCDAD\"\n]\n\n# Feature Engineering\ndf[\"Cardio_Risk\"] = df[\"DIABETES\"].astype(float) + df[\"HYPERTEN\"].astype(float) + df[\"NACCBMI\"].astype(float)\ndf[\"Age_Education_Ratio\"] = df[\"NACCAGE\"].astype(float) / (df[\"EDUC\"].astype(float) + 1)\ndf[\"Lifestyle_Risk\"] = df[\"TOBAC100\"].astype(float) + df[\"ALCOHOL\"].astype(float)\ndf[\"APOE_Risk\"] = (2*(df[\"NACCNE4S\"] == 2)).astype(int) + (df[\"NACCNE4S\"] == 1).astype(int)\ndf[\"Cognitive_Risk\"] = (0.5 * df[\"MEMORY\"] ) * (df[\"Age_Education_Ratio\"])\ndf[\"SEX\"] = df[\"SEX\"].map({1: 0, 2: 1})\n# Define features and target\n\nengineered_features = [\"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\",\"Cognitive_Risk\"]\n\n\nfeature_list = original_features + engineered_features\nX = df[feature_list]\ny = df[\"DEMENTED\"]\n\n# Identify numerical and categorical columns\nnumerical_cols = [\"NACCAGE\", \"EDUC\", \"NACCBMI\", \"NACCMOCA\",\n                  \"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\",\"Cognitive_Risk\"]\nbinary_cols = [\"SEX\", \"TOBAC100\", \"DEP2YRS\",\"DEPOTHR\" \"NACCFAM\",\"NACCMOM\",\"NACCDAD\"]  # No One-Hot Encoding\ncategorical_cols = [ \"NACCNIHR\", \"ALCOHOL\",\"NACCTBI\"\n                    \"DIABETES\", \"HYPERTEN\", \"CVHATT\",\n                    \"SEIZURES\", \"HYPERCHO\",\"CBSTROKE\",\"CVAFIB\"]\n\n# ================================\n# 2. Preprocessing Pipelines\n# ================================\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\nbinary_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent'))  # No encoding needed\n])\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', numerical_pipeline, numerical_cols),\n    ('bin', binary_pipeline, binary_cols),\n    ('cat', categorical_pipeline, categorical_cols)\n])\n\n# ================================\n# 3. Train-Test Split\n# ================================\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n\n# Fit preprocessor\npreprocessor.fit(X_train)\nX_train_processed = preprocessor.transform(X_train)\nX_val_processed = preprocessor.transform(X_val)\nX_test_processed = preprocessor.transform(X_test)\n\n# Compute class weights for imbalance handling\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\nclass_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n\n# 5. ANN Model Definition\n# ================================\ndef build_ann_model(input_shape):\n    model = Sequential([\n        Dense(128, activation='relu', input_shape=(input_shape,)),\n        Dropout(0.3),\n        Dense(64, activation='relu'),\n        Dropout(0.2),\n        Dense(32, activation='relu'),\n        Dense(1, activation='sigmoid')  # Binary classification\n    ])\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model\n    \ninput_shape = X_train_processed.shape[1]\nann_model = build_ann_model(input_shape)\n\n# ================================\n# 5. Model Training with Early Stopping\n# ================================\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\nhistory = ann_model.fit(X_train_processed, y_train, \n                        epochs=50, batch_size=32, \n                        validation_data=(X_val_processed, y_val), \n                        callbacks=[early_stopping],\n                        verbose=1)\n\n# ================================\n# 7. Evaluation\n# ================================\ny_proba = ann_model.predict(X_test_processed).flatten()\n\n# Tune threshold for best F1-score\nbest_threshold = 0.3\nbest_f1 = 0\nfor t in np.arange(0.3, 0.6, 0.05):\n    y_temp = (y_proba >= t).astype(int)\n    f1 = f1_score(y_test, y_temp)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_threshold = t\n\nprint(f\"Optimal Threshold: {best_threshold:.2f} with F1-score: {best_f1:.4f}\")\n\n# Apply optimal threshold\ny_pred = (y_proba >= best_threshold).astype(int)\n\n# Classification Report\nprint(\"\\nTest Set Evaluation:\")\nprint(classification_report(y_test, y_pred))\nprint(\"Test Set ROC-AUC Score:\", roc_auc_score(y_test, y_proba))\n\n\n\n# Generate Confusion Matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\n\n# Plot Confusion Matrix\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[\"No Dementia\", \"Dementia\"], \n            yticklabels=[\"No Dementia\", \"Dementia\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T21:53:42.865498Z","iopub.execute_input":"2025-02-15T21:53:42.865940Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_classif\nimport pandas as pd\nimport numpy as np\n\n# ================================\n# 1. Load Dataset and Preprocess\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visits\ndf = df[df[\"NACCVNUM\"] == 1]\n\n# Feature selection (original + additional features)\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOCCAS\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMMSE\", \"NACCTBI\", \"CVHATT\",\n    \"CVAFIB\", \"PD\", \"SEIZURES\", \"TRAUMBRF\", \"HYPERCHO\", \"MEMORY\"\n]\n\n# Define target variable\nX = df[original_features]\ny = df[\"DEMENTED\"]\n\n# Convert categorical variables to numerical (for mutual information)\nX = X.copy()\nfor col in X.select_dtypes(include=['object', 'category']).columns:\n    X[col], _ = X[col].factorize()\n\n# Impute missing values with median\nX.fillna(X.median(), inplace=True)\n\n# ================================\n# 2. Compute Mutual Information\n# ================================\nmi_scores = mutual_info_classif(X, y, discrete_features='auto')\n\n# Create DataFrame for better visualization\nmi_df = pd.DataFrame({'Feature': original_features, 'Mutual Information': mi_scores})\nmi_df = mi_df.sort_values(by='Mutual Information', ascending=False)\n\n# Display ranked features\nprint(mi_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T09:14:36.108045Z","iopub.status.idle":"2025-02-15T09:14:36.108317Z","shell.execute_reply":"2025-02-15T09:14:36.108188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n# ================================\n# 1. Load and Preprocess Dataset\n# ================================\ndf = pd.read_csv(\"/kaggle/input/nacccsv/investigator_nacc68.csv\")  # Replace with actual file path\n\n# Define missing value codes\nmissing_values = [88, 888, 9, 99, 999, -4.4, -4]\ndf.replace(missing_values, np.nan, inplace=True)\n\n# Keep only baseline visits\ndf = df[df[\"NACCVNUM\"] == 1]\n\n# Feature selection (original + additional features)\noriginal_features = [\n    \"NACCAGE\", \"SEX\", \"NACCNIHR\", \"EDUC\", \"NACCFAM\", \"TOBAC100\", \"ALCOCCAS\",\n    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCBMI\", \"NACCMMSE\", \"NACCTBI\", \"CVHATT\",\n    \"CVAFIB\", \"PD\", \"SEIZURES\", \"TRAUMBRF\", \"HYPERCHO\", \"MEMORY\"\n]\n\n# Feature Engineering\ndf[\"Cardio_Risk\"] = df[\"DIABETES\"].astype(float) + df[\"HYPERTEN\"].astype(float) + df[\"NACCBMI\"].astype(float)\ndf[\"Age_Education_Ratio\"] = df[\"NACCAGE\"].astype(float) / (df[\"EDUC\"].astype(float) + 1)\ndf[\"Lifestyle_Risk\"] = df[\"TOBAC100\"].astype(float) + df[\"ALCOCCAS\"].astype(float)\ndf[\"APOE_Risk\"] = (df[\"NACCNE4S\"] == 2).astype(int) + (df[\"NACCNE4S\"] == 1).astype(int) * 0.5\ndf.drop(columns=[\"NACCNE4S\"], inplace=True)\n\n# Define features and target\nengineered_features = [\"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\"]\nfeature_list = original_features + engineered_features\nX = df[feature_list]\ny = df[\"DEMENTED\"]\n\n# Identify numerical and categorical columns\nnumerical_cols = [\"NACCAGE\", \"EDUC\", \"NACCBMI\", \"NACCMMSE\",\n                  \"Cardio_Risk\", \"Age_Education_Ratio\", \"Lifestyle_Risk\", \"APOE_Risk\"]\ncategorical_cols = [\"SEX\", \"NACCNIHR\", \"NACCFAM\", \"TOBAC100\", \"ALCOCCAS\",\n                    \"DIABETES\", \"HYPERTEN\", \"DEP2YRS\", \"NACCTBI\", \"CVHATT\",\n                    \"CVAFIB\", \"PD\", \"SEIZURES\", \"TRAUMBRF\", \"HYPERCHO\", \"MEMORY\"]\n\n# ================================\n# 2. Preprocessing Pipelines\n# ================================\nnumerical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', numerical_pipeline, numerical_cols),\n    ('cat', categorical_pipeline, categorical_cols)\n])\n\n# Fit transformer to extract feature names\npreprocessor.fit(X)\n\n# Get transformed feature names (handle one-hot encoding)\nnum_feature_names = numerical_cols\ncat_feature_names = preprocessor.named_transformers_['cat'].named_steps['encoder'].get_feature_names_out(categorical_cols)\nall_feature_names = list(num_feature_names) + list(cat_feature_names)\n\n# Apply preprocessing\nX_processed = preprocessor.transform(X)\n\n# ================================\n# 3. Compute Mutual Information\n# ================================\nmi_scores = mutual_info_classif(X_processed, y, discrete_features='auto')\n\n# Create DataFrame for visualization\nmi_df = pd.DataFrame({'Feature': all_feature_names, 'Mutual Information': mi_scores})\nmi_df = mi_df.sort_values(by='Mutual Information', ascending=False)\n\n# Display results\nprint(\"\\nMutual Information Scores:\")\nprint(mi_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T09:14:38.472524Z","iopub.execute_input":"2025-02-15T09:14:38.472840Z","iopub.status.idle":"2025-02-15T09:14:41.446501Z","shell.execute_reply.started":"2025-02-15T09:14:38.472819Z","shell.execute_reply":"2025-02-15T09:14:41.445377Z"}},"outputs":[],"execution_count":null}]}